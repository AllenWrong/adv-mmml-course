- date: 1/21
  title: >
    Week 1: <strong>Course introduction</strong>
  slides:
  topics:
    - Course syllabus and requirements
  readings: N/A

- date: 1/28
  title: >
    Week 2: <strong>Cross-modal interactions</strong>
  topics:
    - What are the different ways in which modalities can interact with each other in multimodal tasks? Can we formalize a taxonomy of such cross-modal interactions, which will enable us to compare and contrast them more precisely? <br/>
    - What are the design decisions (aka inductive biases) that can be used when modeling these cross-modal interactions in machine learning models? <br/>
    - What are the advantages and drawbacks of designing models to capture each type of cross-modal interaction? Consider not just prediction performance, but tradeoffs in time/space complexity, interpretability, and so on. <br/>
    - Given an arbitrary dataset and prediction task, how can we systematically decide what type of cross-modal interactions exist, and how can that inform our modeling decisions? <br/>
    - Given trained multimodal models, how can we understand or visualize the nature of cross-modal interactions? <br/>
  readings:
    - <a href="https://aclanthology.org/2020.emnlp-main.62/">Does my multimodal model learn cross-modal interactions? It’s harder to tell than you might think!</a> <br/>
    - <a href="https://aclanthology.org/2020.acl-main.469.pdf">What Does BERT with Vision Look At?</a> <br/>
    - <a href="https://openreview.net/pdf?id=rylnK6VtDH">Multiplicative Interactions and Where to Find Them</a> <br/>
    - <a href="https://arxiv.org/abs/2112.12337">Cooperative Learning for Multi-view Analysis</a> <br/>
    - <a href="https://arxiv.org/abs/2109.04448">Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in Multimodal Transformers</a> <br/>
    - <a href="https://arxiv.org/abs/2012.12352">Seeing past words\: Testing the cross-modal capabilities of pretrained V&L models on counting tasks</a> <br/>
- date: 2/4
  title: >
    Week 3: <strong>Multimodal co-learning</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 2/11
  title: >
    Week 4: <strong>Pretraining paradigm</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 2/18
  title: >
    Week 5: <strong>Multimodal reasoning</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 2/25
  title: >
    Week 6: <strong>Memory and long-term interactions</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 3/4
  title: >
    Week 7: <strong>No classes – Spring break</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 3/11
  title: >
    Week 8: <strong>No classes – Spring break</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 3/18
  title: >
    Week 9: <strong>Brain and multimodal perception</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 3/25
  title: >
    Week 10: <strong>Beyond language and vision</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 4/1
  title: >
    Week 11: <strong>Subjectivity and dataset biases</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 4/8
  title: >
    Week 12: <strong>No classes – CMU Carnival</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 4/15
  title: >
    Week 13: <strong>Fairness and real-world constraints</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 4/22
  title: >
    Week 14: <strong>Multimodal generalization</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 4/29
  title: >
    Week 15: <strong>Low-resource settings</strong>
  slides:
  topics:
    - TBD
  readings: TBD
