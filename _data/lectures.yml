- date: 1/21
  title: >
    Week 1: <strong>Course introduction</strong>
  slides:
  topics:
    - Course syllabus and requirements
  readings: TBD

- date: 1/28
  title: >
    Week 2: <strong>Cross-modal interactions</strong> <br/>
    - * What are the different ways in which modalities can interact with each other in multimodal tasks? Can we formalize a taxonomy of such cross-modal interactions, which will enable us to compare and contrast them more precisely? <br/>
    - * What are the design decisions (aka inductive biases) that can be used when modeling these cross-modal interactions in machine learning models? <br/>
    - * What are the advantages and drawbacks of designing models to capture each type of cross-modal interaction? Consider not just prediction performance, but tradeoffs in time/space complexity, interpretability, and so on. <br/>
    - * Given an arbitrary dataset and prediction task, how can we systematically decide what type of cross-modal interactions exist, and how can that inform our modeling decisions? <br/>
    - * Given trained multimodal models, how can we understand or visualize the nature of cross-modal interactions?
  topics:
    - * Additive interactions: [Does my multimodal model learn cross-modal interactions? It’s harder to tell than you might think!](https://aclanthology.org/2020.emnlp-main.62/) <br/>
    - * Grounding interactions: [What Does BERT with Vision Look At?](https://aclanthology.org/2020.acl-main.469.pdf) <br/>
    - * Multiplicative interactions: [Multiplicative Interactions and Where to Find Them](https://openreview.net/pdf?id=rylnK6VtDH) <br/>
    - * Cooperative interactions: [Cooperative Learning for Multi-view Analysis](https://arxiv.org/pdf/2112.12337.pdf) <br/>
    - * Visualizations and ablations: [Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in Multimodal Transformers](https://arxiv.org/abs/2109.04448) <br/>
    - * Visualizations and ablations: [Seeing past words: Testing the cross-modal capabilities of pretrained V&L models on counting tasks](https://arxiv.org/abs/2012.12352)
    
  readings: TBD

- date: 2/4
  title: >
    Week 3: <strong>Multimodal co-learning</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 2/11
  title: >
    Week 4: <strong>Pretraining paradigm</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 2/18
  title: >
    Week 5: <strong>Multimodal reasoning</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 2/25
  title: >
    Week 6: <strong>Memory and long-term interactions</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 3/4
  title: >
    Week 7: <strong>No classes – Spring break</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 3/11
  title: >
    Week 8: <strong>No classes – Spring break</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 3/18
  title: >
    Week 9: <strong>Brain and multimodal perception</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 3/25
  title: >
    Week 10: <strong>Beyond language and vision</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 4/1
  title: >
    Week 11: <strong>Subjectivity and dataset biases</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 4/8
  title: >
    Week 12: <strong>No classes – CMU Carnival</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 4/15
  title: >
    Week 13: <strong>Fairness and real-world constraints</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 4/22
  title: >
    Week 14: <strong>Multimodal generalization</strong>
  slides:
  topics:
    - TBD
  readings: TBD
  
- date: 4/29
  title: >
    Week 15: <strong>Low-resource settings</strong>
  slides:
  topics:
    - TBD
  readings: TBD
