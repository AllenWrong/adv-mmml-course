- date: 1/20
  title: >
    Week 1: <strong>Course introduction</strong> <a href="lecture1-Introduction.pdf">[slides]</a>
  slides:
  topics:
    - Course syllabus and requirements
    - Multimodal principles&#58; heterogeneity, connections, and interactions
    - Multimodal technical challenges
  readings:
    - <a href="https://arxiv.org/abs/2209.03430">Foundations and Recent Trends in Multimodal Machine Learning&#58; Principles, Challenges, and Open Questions</a> <br/>
    - <a href="https://arxiv.org/abs/1705.09406">Multimodal Machine Learning&#58; A Survey and Taxonomy</a> <br/>
    - <a href="https://arxiv.org/abs/1206.5538">Representation Learning&#58; A Review and New Perspectives</a> <br/>

- date: 1/27
  title: >
    Week 2: <strong>Dimensions of heterogeneity</strong> <a href="11877_week2.pdf">[synopsis]</a>
  topics:
    - What is a taxonomy of the dimensions in which modalities can be heterogeneous?
    - Heterogeneity is also often seen in several other ML subfields (e.g., domain adaptation, domain shift, transfer learning, multitask learning, federated learning, etc). What are some similarities and differences between the notions of heterogeneity between MMML and these fields? Can definitions or methods in each area be adapted to benefit other research areas?
    - How can we formalize these dimensions of heterogeneity, and subsequently estimate these measures to quantify the degree in which modalities are different?
    - Modality heterogeneity often implies the design of specialized models capturing the unique properties of each modality. What are some tradeoffs in modality-specific vs modality-general models?
    - What are other modeling considerations that ideally should be informed based on how heterogeneous the input modalities are?
    - What are some risks if we were to ignore modality or task heterogeneity? What if we are unable to estimate modality or task heterogeneity accurately?
  readings:
    - <a href="https://arxiv.org/abs/2104.13478">Geometric Deep Learning&#58; Grids, Groups, Graphs, Geodesics, and Gauges</a> <br/>
    - <a href="https://link.springer.com/article/10.1186/s40537-017-0089-0">A Survey on Heterogeneous Transfer Learning</a> <br/>
    - <a href="https://arxiv.org/abs/1804.08328">Taskonomy&#58; Disentangling Task Transfer Learning</a> <br/>
    - <a href="https://arxiv.org/abs/1905.07553">Which Tasks Should Be Learned Together in Multi-task Learning?</a> <br/>
    - <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9084352">Federated Learning&#58; Challenges, Methods, and Future Directions</a> <br/>
    - <a href="http://proceedings.mlr.press/v28/zhang13d.pdf">Domain Adaptation under Target and Conditional Shift</a> <br/>
    - <a href="https://arxiv.org/abs/1802.03916">Detecting and Correcting for Label Shift with Black Box Predictors</a> <br/>
    - <a href="https://arxiv.org/abs/2002.02923">Geometric Dataset Distances via Optimal Transport</a> <br/>
    - <a href="https://arxiv.org/abs/2203.01311">HighMMT&#58; Quantifying Modality & Interaction Heterogeneity for High-Modality Representation Learning</a> <br/>
    - <a href="https://link.springer.com/content/pdf/10.1023/A:1007379606734.pdf">Multitask Learning</a> <br/>
    - <a href="https://link.springer.com/chapter/10.1007/978-3-540-45167-9_41">Exploiting Task Relatedness for Multiple Task Learning</a> <br/>
    
- date: 2/3
  title: >
    Week 3: <strong>Modality connections</strong>
  topics:
    - What are the reasons why modalities can be connected with each other? Come up with a taxonomy of various dimensions. Think along both statistical, data-driven dimensions and semantic, hypothesis or knowledge driven dimensions. What are the pros and cons of either approach in understanding modality connections?
    - Are connections always strong and one-to-one? Reflect on what could make some cross-modal connections stronger or weaker, including many-to-many connections, ambiguity or noises?
    - Given trained multimodal models, how can we understand or visualize the nature of connections captured by the model?
    - What formalism or framework could be used to formalize cross-modal connections? How can we subsequently define estimators, where we can accurately quantify the presence of each type of connection given a dataset? How much knowledge of each modality do we need in order to estimate modality connections?
    - Linking back to week 1’s discussion on heterogeneity, how would you relate the concepts of heterogeneity and connections? How is heterogeneity affecting the study of crossmodal connections and inversely, how connections should be taken into consideration when heterogeneity is studied? Are connections also present in homogenous settings?
  readings:
    - <a href="https://arxiv.org/abs/2005.10243">What Makes for Good Views for Contrastive Learning?</a> <br/>
    - <a href="https://link.springer.com/article/10.1007/s13735-019-00187-6">Characterization and classification of semantic image-text relations</a> <br/>
    - <a href="https://www.emerald.com/insight/content/doi/10.1108/00220410310506303/full/pdf?title=a-taxonomy-of-relationships-between-images-and-text">A taxonomy of relationships between images and text</a> <br/>
    - <a href="https://arxiv.org/abs/1511.06361">Order-Embeddings of Images and Language</a> <br/>
    - <a href="https://link.springer.com/content/pdf/10.1007/s10994-005-0913-1.pdf">Corpus-based Learning of Analogies and Semantic Relations</a> <br/>
    - <a href="https://distill.pub/2021/multimodal-neurons/">Multimodal Neurons in Artificial Neural Networks</a> <br/>
    - <a href="https://arxiv.org/abs/1607.07295">Learning Aligned Cross-Modal Representations from Weakly Aligned Data</a> <br/>
    - <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9363924">Toward Causal Representation Learning</a> <br/>
    - <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358050">A Review of Relational Machine Learning for Knowledge Graphs</a> <br/>
    - <a href="https://chinese.wooster.edu/files/barthes.pdf">Image-Music-Text</a> <br/>
    - <a href="https://arxiv.org/abs/1805.11222">Unsupervised Alignment of Embeddings with Wasserstein Procrustes</a> <br/>
    - <a href="https://arxiv.org/abs/1905.06922">On Variational Bounds of Mutual Information</a> <br/>
    - <a href="https://journals.sagepub.com/doi/epdf/10.1177/1470357205055928">A system for image–text relations in new (and old) media</a> <br/>
  
- date: 2/10
  title: >
    Week 4: <strong>Modality interactions</strong>
  topics:
    - What are the different ways in which modalities can interact with each other when used for a prediction tasks? Think across both semantic and statistical perspectives. Can we formalize a taxonomy of such interactions, which will enable us to compare and contrast them more precisely? In fact, should we even try creating such a taxonomy?
    - Can you think of ways modalities could interact with each others, even if there is no prediction task? How are modalities interacting during cross-modal translation? During multimodal generation?
    - Linking back to last week’s discussion, are there cases where modalities are connected but do not interact? Or interact but are not connected? Can we design formal experiments to test either hypotheses?
    - What mathematical or empirical frameworks can be used to formalize the meaning of interactions? How can we subsequently define estimators, where we can accurately quantify the presence of each type of interactions given a dataset?
    - Some definitions (from the semantic category) typically require human interactions to detect and quantify interactions. What are some opportunities and limitations of using human judgment to analyze interactions? Can we potentially design estimators to automate the human labeling process?
    - What are the design decisions (aka inductive biases) that can be used when modeling each type of interaction in machine learning models?
    - What are the advantages and drawbacks of designing models to capture each type of cross-modal interaction? Consider not just prediction performance, but tradeoffs in time/space complexity, interpretability, etc.
  readings:
    - <a href="https://www.journals.uchicago.edu/doi/epdf/10.1086/431246">Issues in the Classification of Multimodal Communication Signals</a> <br/>
    - <a href="https://arxiv.org/abs/1004.2515">Nonnegative Decomposition of Multivariate Information</a> <br/>
    - <a href="https://www.sciencedirect.com/science/article/pii/S0378216608003056">Language and image interaction in cartoons&#58; Towards a multimodal theory of humor</a> <br/>
    - <a href="https://piazza.com/class_profile/get_resource/lcv0w9mqjzy1kx/lds3ewt4t4g6w4">Multimodality and reading&#58; The construction of meaning through image-text interaction</a> <br/>
    - <a href="https://dl.acm.org/doi/abs/10.1145/1228175.1228254">Examining the redundancy of multimodal input</a> <br/>
    - <a href="https://aclanthology.org/2020.emnlp-main.62/">Does my multimodal model learn cross-modal interactions? It’s harder to tell than you might think!</a> <br/>
    - <a href="https://drive.google.com/file/d/1txIMRy3AAiS7qDCmayzfsN3HmjPipVjd/view?usp=share_link">Quantifying & Modeling Feature Interactions&#58; An Information Decomposition Framework</a> <br/>
    - <a href="https://arxiv.org/abs/2006.10965">How does this interaction affect me? Interpretable attribution for feature interactions</a> <br/>
    - <a href="https://arxiv.org/abs/cs/0308002">Quantifying and Visualizing Attribute Interactions</a> <br/>
    - <a href="https://www.sesp.org/files/The%20Moderator-Baron.pdf">The Moderator-Mediator Variable Distinction in Social Psychological Research&#58; Conceptual, Strategic, and Statistical Considerations</a> <br/>

- date: 2/17
  title: >
    Week 5: <strong>Modality utility and selection</strong>
  topics:
  
  readings:

- date: 2/24
  title: >
    Week 6: <strong>Quantification and visualization</strong>
  topics:
  
  readings:

- date: 3/3
  title: >
    Week 7: <strong>Empirical and theoretical frameworks</strong>
  topics:
  
  readings:
  
- date: 3/10
  title: >
    Week 8: <strong>No classes – Spring break</strong>
  topics:
    - None!
  readings:
    - None!

- date: 3/17
  title: >
    Week 9: <strong>Brain and multimodal perception</strong>
  topics:
  
  readings:
  
- date: 3/24
  title: >
    Week 10: <strong>Multimodal reasoning</strong>
  topics:
  
  readings:
  
- date: 3/31
  title: >
    Week 11: <strong>Pretraining and scaling</strong>
  topics:
  
  readings:

- date: 4/7
  title: >
    Week 12: <strong>No classes – CMU Carnival</strong>
  topics:
    - None!
  readings:
    - None!
  
- date: 4/14
  title: >
    Week 13: <strong>Generalization and optimization</strong>
  topics:
  
  readings:
  
- date: 4/21
  title: >
    Week 14: <strong>Open research questions</strong>
  topics:
  
  readings:
  
- date: 4/28
  title: >
    Week 15: <strong>Project presentations</strong>
  topics:
  
  readings:
